{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "cc34bd72-a213-4be9-bcff-8504c4407c08",
      "metadata": {
        "id": "cc34bd72-a213-4be9-bcff-8504c4407c08"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "from collections import defaultdict\n",
        "import json\n",
        "import sys\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "c684cb9f-024c-4ec4-9dbf-137c9c49e608",
      "metadata": {
        "id": "c684cb9f-024c-4ec4-9dbf-137c9c49e608"
      },
      "outputs": [],
      "source": [
        "def load_dataframe(path):\n",
        "    return pd.read_csv(path)\n",
        "\n",
        "def load_user_data(usr_df, label, embedding_type=None, time_step='week'):\n",
        "    \"\"\"\n",
        "    args:\n",
        "        usr_df: DataFrame containing each user's weekly/daily data per row\n",
        "        label: String for which field to treat as label\n",
        "        embedding_type: String to toggle between 'w2v' or 'bert'. Default is univariate forecast\n",
        "        time_step: String to toggle between week or daily data. Using the column name(week or day_id)\n",
        "    return:\n",
        "        dictionary of key = user_id and value = sequence of user data over all available time\n",
        "    \"\"\"\n",
        "    usr_dict = defaultdict(list)\n",
        "\n",
        "    for idx,row in usr_df.iterrows(): # load all users and format into dictionary\n",
        "        if embedding_type:\n",
        "            embedding = np.array(json.loads(row[embedding_type])) # embeddings are stored as json\n",
        "\n",
        "\n",
        "        target = row[label]\n",
        "\n",
        "        try:\n",
        "            other_vars = embedding\n",
        "        except:\n",
        "            other_vars = []\n",
        "\n",
        "        # append other variables here if desired (i.e. intensity along with embeddings for Aff pred)\n",
        "        # if label = 'affect':\n",
        "        #   other_vars.append(row['intensity'])\n",
        "\n",
        "        if time_step == 'week':\n",
        "            key = 'week'\n",
        "        else:\n",
        "            key = 'day_id'\n",
        "\n",
        "        if len(other_vars) > 0:\n",
        "            usr_data = (row[key], np.append(target, other_vars))\n",
        "        else:\n",
        "            usr_data = (row[key], target)\n",
        "\n",
        "        usr_dict[row['user_id']].append(usr_data)\n",
        "\n",
        "    return usr_dict\n",
        "\n",
        "def gen_train_data(user_data, n):\n",
        "    \"\"\"\n",
        "    args:\n",
        "        user_data: Dictionary containing each user's full history as a sequence\n",
        "        n: Integer denoting the maximum history to use for the model\n",
        "    return:\n",
        "        train_data: numpy array of chunked user history\n",
        "        train_labels: numpy array of label per user history sequence\n",
        "    \"\"\"\n",
        "\n",
        "    train_data, labels = [], []\n",
        "    for k,v in user_data.items():\n",
        "        usr_all_history = user_data[k][:15] # eahc user has maximum 14 time-steps\n",
        "        usr_train_data = []\n",
        "        usr_train_labels = []\n",
        "\n",
        "        for i in range(15-n): # only go back as far as n\n",
        "            curr_train = []\n",
        "            curr_label = []\n",
        "            for j in range(n): # for each time-step\n",
        "                if j < n - 1:\n",
        "                    curr_train.append(usr_all_history[j+i][1])\n",
        "                elif j == n -1:\n",
        "                    curr_train.append(usr_all_history[j+i][1])\n",
        "\n",
        "                    # assumes multi-variate, catches univariate case\n",
        "                    # [0] grabs the target which is always first element of that week\n",
        "                    try:\n",
        "                        curr_label.append(usr_all_history[j+i+1][1][0])\n",
        "                        features = [f for week in curr_train for f in week]\n",
        "                    except:\n",
        "                        curr_label.append(usr_all_history[j+i+1][1])\n",
        "                        features = [f for f in curr_train]\n",
        "\n",
        "            train_data.append(features)\n",
        "            labels.append(curr_label[0])\n",
        "\n",
        "    return np.array(train_data), np.array(labels)\n",
        "\n",
        "def gen_test_data(user_data, n):\n",
        "    \"\"\"\n",
        "    args:\n",
        "        user_data: Dictionary containing each user's full history as a sequence\n",
        "        n: Integer denoting the maximum history to use for the model\n",
        "    return:\n",
        "        test_data: numpy array of chunked user history\n",
        "        test_labels: numpy array of label per user history sequence\n",
        "    \"\"\"\n",
        "    test_data, test_labels = [], []\n",
        "    for k,v in user_data.items():\n",
        "        usr_test_history = user_data[k][-5:] # Grab remaining weeks in user's sequence for testing\n",
        "        usr_test_data = []\n",
        "        usr_test_labels = []\n",
        "        for i in range(4): # 4 test weeks\n",
        "            features = []\n",
        "            for j in range(1,n):\n",
        "                features = np.append(user_data[k][:][(-5+i)-j][1], features)\n",
        "\n",
        "            usr_test_embeds = np.append(features, usr_test_history[i][1])\n",
        "            test_data.append(usr_test_embeds)\n",
        "\n",
        "            try:\n",
        "                test_labels.append(usr_test_history[i+1][1][0])\n",
        "            except:\n",
        "                test_labels.append(usr_test_history[i+1][1])\n",
        "\n",
        "    return test_data, test_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "9fe330bc-8919-4c90-bebd-3601ca0171ce",
      "metadata": {
        "id": "9fe330bc-8919-4c90-bebd-3601ca0171ce"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import numpy as np\n",
        "from os import listdir\n",
        "import pandas as pd\n",
        "import json\n",
        "from sklearn.linear_model import Ridge\n",
        "import argparse\n",
        "import copy\n",
        "from scipy.stats import sem\n",
        "from scipy.stats import pearsonr\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import sys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "bf966885-59e8-498d-8fb0-6c581a721fb2",
      "metadata": {
        "id": "bf966885-59e8-498d-8fb0-6c581a721fb2"
      },
      "outputs": [],
      "source": [
        "df = load_dataframe('weekly_all_labels.csv')\n",
        "usr_seqs = load_user_data(df, 'affect', embedding_type=\"bert\")\n",
        "train_data, train_labels = gen_train_data(usr_seqs, 10)\n",
        "test_data, test_labels = gen_test_data(usr_seqs, 10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "69b8d590-89a6-4366-b00b-0ccbc223bf80",
      "metadata": {
        "id": "69b8d590-89a6-4366-b00b-0ccbc223bf80"
      },
      "outputs": [],
      "source": [
        "train_set, train_gp, running_mae = pd.read_pickle(\"GP_results_4mix.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "5c7c9ded-8836-4f8b-ba4c-638a740bd73e",
      "metadata": {
        "id": "5c7c9ded-8836-4f8b-ba4c-638a740bd73e"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer\n",
        "imp = IterativeImputer(max_iter=10, random_state=0) #\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "386dd37c-d936-4874-b439-f77c1caed25e",
      "metadata": {
        "id": "386dd37c-d936-4874-b439-f77c1caed25e"
      },
      "outputs": [],
      "source": [
        "def fixtensor(x,y):\n",
        "    x = x.tolist()\n",
        "    y = y.tolist()\n",
        "    x = x - np.min(x)\n",
        "\n",
        "\n",
        "    fixed_x = list(range(60))\n",
        "    fixed_y = [np.nan]*60\n",
        "    for ii in range(len(x)):\n",
        "        fixed_y[x[ii]] = y[ii]\n",
        "\n",
        "    z = np.array([fixed_x,fixed_y]).transpose()\n",
        "    imp.fit(z)\n",
        "    zz = imp.transform(z)\n",
        "\n",
        "    return zz.transpose()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_df(train_set,train_gp):\n",
        "    true_data = []\n",
        "    gp_data = []\n",
        "    true_labels = []\n",
        "    gp_labels = []\n",
        "    for ii in range(len(train_set)):\n",
        "        true_data.append(fixtensor(train_set[ii][0][0][0],train_set[ii][0][1][0])[1])\n",
        "        gp_data.append(fixtensor(train_set[ii][0][0][0],train_gp[ii][0][0])[1])\n",
        "        true_labels.append(train_set[ii][0][1][1].tolist()[0])\n",
        "        gp_labels.append(train_gp[ii][1][0].tolist()[0])\n",
        "\n",
        "    true_data = np.array(true_data)\n",
        "    true_labels = np.array(true_labels)\n",
        "    gp_data = np.array(gp_data)\n",
        "    gp_labels = np.array(gp_labels)\n",
        "\n",
        "    test_data = true_data[-100:]\n",
        "    test_labels = true_labels[-100:]\n",
        "    test_gp_data = gp_data[-100:]\n",
        "    test_gp_labels = gp_labels[-100:]\n",
        "\n",
        "    train_data = true_data[:-100]\n",
        "    train_labels = true_labels[:-100]\n",
        "    train_gp_data = gp_data[:-100]\n",
        "    train_gp_labels = gp_labels[:-100]\n",
        "\n",
        "    train_df = pd.DataFrame(train_data)\n",
        "    train_labels_df = pd.DataFrame(train_labels)\n",
        "    train_labels_df.columns = ['label']\n",
        "    train_labels_df['label'] = train_labels_df['label'].astype(float)\n",
        "\n",
        "    train_gp_df = pd.DataFrame(train_gp_data)\n",
        "    train_gp_labels_df = pd.DataFrame(train_gp_labels)\n",
        "    train_gp_labels_df.columns = ['label']\n",
        "    train_gp_labels_df['label'] = train_gp_labels_df['label'].astype(float)\n",
        "\n",
        "    test_df = pd.DataFrame(test_data)\n",
        "    test_labels_df = pd.DataFrame(test_labels)\n",
        "    test_labels_df.columns = ['label']\n",
        "    test_labels_df['label'] = test_labels_df['label'].astype(float)\n",
        "\n",
        "    test_gp_data = pd.DataFrame(test_gp_data)\n",
        "    test_gp_labels = pd.DataFrame(test_gp_labels)\n",
        "    test_gp_labels.columns = ['label']\n",
        "    test_gp_labels['label'] = test_gp_labels['label'].astype(float)\n",
        "\n",
        "    return train_df, train_labels_df, train_gp_df, train_gp_labels_df, test_df, test_labels_df, test_gp_data, test_gp_labels"
      ],
      "metadata": {
        "id": "de4goVzxKka2"
      },
      "id": "de4goVzxKka2",
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def smape(A, F):\n",
        "    return 100/len(A) * np.sum(2 * np.abs(F - A) / (np.abs(A) + np.abs(F)))"
      ],
      "metadata": {
        "id": "t3PXjjQANWFj"
      },
      "id": "t3PXjjQANWFj",
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "true_res = []\n",
        "gp_res = []\n",
        "\n",
        "for ii in range(9):\n",
        "    train_set, train_gp, running_mae = pd.read_pickle(\"GP_results_\" + str(ii+4) + \"mix.pkl\")\n",
        "    train_df, train_labels_df, train_gp_df, train_gp_labels_df, test_df, test_labels_df, test_gp_data, test_gp_labels = build_df(train_set,train_gp)\n",
        "    model = Ridge(alpha=.01)\n",
        "    model_gp = Ridge(alpha=.01)\n",
        "    model.fit(train_df, train_labels_df.label)\n",
        "    model_gp.fit(train_gp_df, train_gp_labels_df.label)\n",
        "\n",
        "    true_preds = model.predict(test_df)\n",
        "    true_mse = mean_squared_error(test_labels, true_preds)\n",
        "    true_corr = np.corrcoef(test_labels, true_preds)[0,1]\n",
        "    true_smape = smape(test_labels, true_preds)\n",
        "    true_res.append((true_corr,true_mse,true_smape))\n",
        "\n",
        "    gp_preds = model_gp.predict(test_df)\n",
        "    gp_mse = mean_squared_error(test_labels,gp_preds)\n",
        "    gp_corr = np.corrcoef(test_labels, gp_preds)[0,1]\n",
        "    gp_smape = smape(test_labels, gp_preds)\n",
        "    gp_res.append((gp_corr,gp_mse,gp_smape))"
      ],
      "metadata": {
        "id": "ssil0IMdNIWx"
      },
      "id": "ssil0IMdNIWx",
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "true_res[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CRy7sontNVgI",
        "outputId": "52b8b8b6-3137-41cd-984e-90d0c43390fc"
      },
      "id": "CRy7sontNVgI",
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.8185047838131291, 0.178172926846121, 16.47476100781459)"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}